@LoginWithAdmin @Regression @DeleteTestCatalog
Feature: Add all model types

  Scenario Outline: Create '<MODEL>' model and validate its SMSS properties
    Given User opens Main Menu
    When User clicks on Open Model
    And User clicks on Add Model
    And User clicks on the '<GROUP>' tab
    And User selects '<MODEL>'
    Then User can see following form sections with fields:
      | SECTION_NAME | FIELDS      |
      | <S1_NAME>    | <S1_FIELDS> |
      | <S2_NAME>    | <S2_FIELDS> |
      | <S3_NAME>    | <S3_FIELDS> |
    And User can see following fields are mandatory fields
      | <MANDATORY_FIELDS> |
    When User fills the model creation form with:
      | <FORM_FIELDS> |
    Then User can see 'Connect' button becomes enabled
    When User clicks on 'Connect' button
    Then User can see a toast message as 'Successfully added LLM to catalog'
    When User clicks on Copy Catalog ID
    Then User can see the Model title as '<CATALOG_NAME>'
    When User clicks on SMSS
    Then User can see following fields in SMSS Properties
      | <SMSS_FIELDS> |

    Examples: 
      | GROUP            | MODEL                         | S1_NAME | S1_FIELDS                      | S2_NAME     | S2_FIELDS                                        | S3_NAME  | S3_FIELDS                                                                                                                                                    | MANDATORY_FIELDS                                                                                                            | FORM_FIELDS                                                                                                                                                                                                                                                                                      | CATALOG_NAME             | SMSS_FIELDS                                                                                                                                                                                                                                                    |
      | OpenAI           | Other OpenAI models           | General | Catalog Name, Model, Chat Type | Credentials | Open AI Key                                      | Settings | Max Completion Tokens, Max Input Tokens, Context Window, Record Questions and Responses, Keep Conversation History, Init Script                              | Catalog Name, Model, Chat Type, Open AI Key, Context Window, Record Questions and Responses, Keep Conversation History      | Catalog Name=Custom OpenAI Model, Model=gpt-3.5, Chat Type=responses, Open AI Key=Test123, Max Completion Tokens=10, Max Input Tokens=20, Context Window=5000, Record Questions and Responses=false, Keep Conversation History=false                                                             | Custom OpenAI Model      | NAME=Custom OpenAI Model, MODEL=gpt-3.5, CHAT_TYPE=responses, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=5000, MAX_TOKENS=10, MAX_INPUT_TOKENS=20                             |
      | OpenAI           | GPT-5                         | General | Catalog Name, Model, Chat Type | Credentials | Open AI Key                                      | Settings | Max Completion Tokens, Max Input Tokens, Context Window, Record Questions and Responses, Keep Conversation History, Init Script                              | Catalog Name, Model, Chat Type, Open AI Key, Context Window, Record Questions and Responses, Keep Conversation History      | Catalog Name=GPT-5-Model, Chat Type=completion, Open AI Key=Test123, Max Completion Tokens=20, Max Input Tokens=30, Context Window=5001, Record Questions and Responses=true, Keep Conversation History=false                                                                                    | GPT-5-Model              | NAME=GPT-5-Model, MODEL=gpt-5, CHAT_TYPE=completion, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=true, CONTEXT_WINDOW=5001, MAX_TOKENS=20, MAX_INPUT_TOKENS=30                                       |
      | OpenAI           | GPT-5.1                       | General | Catalog Name, Model, Chat Type | Credentials | Open AI Key                                      | Settings | Max Completion Tokens, Max Input Tokens, Context Window, Record Questions and Responses, Keep Conversation History, Init Script                              | Catalog Name, Model, Chat Type, Open AI Key, Context Window, Record Questions and Responses, Keep Conversation History      | Catalog Name=GPT-5-1-Model, Chat Type=chat-completion, Open AI Key=Test123, Max Completion Tokens=50, Max Input Tokens=50, Context Window=2048, Record Questions and Responses=true, Keep Conversation History=true                                                                              | GPT-5-1-Model            | NAME=GPT-5-1-Model, MODEL=gpt-5.1, CHAT_TYPE=chat-completion, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=true, CONTEXT_WINDOW=2048, MAX_TOKENS=50, MAX_INPUT_TOKENS=50                               |
      | OpenAI           | GPT-5 Mini                    | General | Catalog Name, Model, Chat Type | Credentials | Open AI Key                                      | Settings | Max Completion Tokens, Max Input Tokens, Context Window, Record Questions and Responses, Keep Conversation History, Init Script                              | Catalog Name, Model, Chat Type, Open AI Key, Context Window, Record Questions and Responses, Keep Conversation History      | Catalog Name=GPT-5-Mini-Model, Chat Type=responses, Open AI Key=Test123, Max Completion Tokens=9, Max Input Tokens=5, Context Window=1000, Record Questions and Responses=false, Keep Conversation History=true                                                                                  | GPT-5-Mini-Model         | NAME=GPT-5-Mini-Model, MODEL=gpt-5-mini, CHAT_TYPE=responses, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=1000, MAX_TOKENS=9, MAX_INPUT_TOKENS=5                                |
      | OpenAI           | GPT-5 nano                    | General | Catalog Name, Model, Chat Type | Credentials | Open AI Key                                      | Settings | Max Completion Tokens, Max Input Tokens, Context Window, Record Questions and Responses, Keep Conversation History, Init Script                              | Catalog Name, Model, Chat Type, Open AI Key, Context Window, Record Questions and Responses, Keep Conversation History      | Catalog Name=GPT-5-Nano-Model, Chat Type=completion, Open AI Key=Test123, Max Completion Tokens=9, Max Input Tokens=5, Context Window=1000, Record Questions and Responses=false, Keep Conversation History=true                                                                                 | GPT-5-Nano-Model         | NAME=GPT-5-Nano-Model, MODEL=gpt-5-nano, CHAT_TYPE=completion, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=1000, MAX_TOKENS=9, MAX_INPUT_TOKENS=5                               |
      | OpenAI           | GPT 4                         | General | Catalog Name, Model, Chat Type | Credentials | Open AI Key                                      | Settings | Max Completion Tokens, Max Input Tokens, Context Window, Record Questions and Responses, Keep Conversation History, Init Script                              | Catalog Name, Model, Chat Type, Open AI Key, Context Window, Record Questions and Responses, Keep Conversation History      | Catalog Name=GPT-4-Model, Chat Type=completion, Open AI Key=Test123, Max Completion Tokens=55, Max Input Tokens=55, Context Window=2000, Record Questions and Responses=true, Keep Conversation History=false                                                                                    | GPT-4-Model              | NAME=GPT-4-Model, MODEL=gpt-4, CHAT_TYPE=completion, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=true, CONTEXT_WINDOW=2000, MAX_TOKENS=55, MAX_INPUT_TOKENS=55                                       |
      | OpenAI           | GPT 3.5 Turbo                 | General | Catalog Name, Model, Chat Type | Credentials | Open AI Key                                      | Settings | Max Completion Tokens, Max Input Tokens, Context Window, Record Questions and Responses, Keep Conversation History, Init Script                              | Catalog Name, Model, Chat Type, Open AI Key, Context Window, Record Questions and Responses, Keep Conversation History      | Catalog Name=GPT-3-5-Turbo-Model, Chat Type=completion, Open AI Key=Test123, Max Completion Tokens=55, Max Input Tokens=55, Context Window=2000, Record Questions and Responses=true, Keep Conversation History=false                                                                            | GPT-3-5-Turbo-Model      | NAME=GPT-3-5-Turbo-Model, MODEL=gpt-3.5-turbo, CHAT_TYPE=completion, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=true, CONTEXT_WINDOW=2000, MAX_TOKENS=55, MAX_INPUT_TOKENS=55                       |
      | OpenAI           | GPT-4o                        | General | Catalog Name, Model, Chat Type | Credentials | Open AI Key                                      | Settings | Max Completion Tokens, Max Input Tokens, Context Window, Record Questions and Responses, Keep Conversation History, Init Script                              | Catalog Name, Model, Chat Type, Open AI Key, Context Window, Record Questions and Responses, Keep Conversation History      | Catalog Name=GPT-4o-Model, Chat Type=completion, Open AI Key=Test123, Max Completion Tokens=55, Max Input Tokens=55, Context Window=2000, Record Questions and Responses=true, Keep Conversation History=false                                                                                   | GPT-4o-Model             | NAME=GPT-4o-Model, MODEL=gpt-4o, CHAT_TYPE=completion, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=true, CONTEXT_WINDOW=2000, MAX_TOKENS=55, MAX_INPUT_TOKENS=55                                     |
      | OpenAI           | DALL E 3                      | General | Catalog Name, Model, Chat Type | Credentials | Open AI Key                                      | Settings | Max Completion Tokens, Max Input Tokens, Context Window, Record Questions and Responses, Keep Conversation History, Init Script                              | Catalog Name, Model, Chat Type, Open AI Key, Context Window, Record Questions and Responses, Keep Conversation History      | Catalog Name=DALL-E-3-Model, Chat Type=chat-completion, Open AI Key=Test123, Max Completion Tokens=50, Max Input Tokens=50, Context Window=2048, Record Questions and Responses=true, Keep Conversation History=true                                                                             | DALL-E-3-Model           | NAME=DALL-E-3-Model, MODEL=dall-e-3, CHAT_TYPE=chat-completion, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=true, CONTEXT_WINDOW=2048, MAX_TOKENS=50, MAX_INPUT_TOKENS=50                             |
      | OpenAI           | DALL E 2                      | General | Catalog Name, Model, Chat Type | Credentials | Open AI Key                                      | Settings | Max Completion Tokens, Max Input Tokens, Context Window, Record Questions and Responses, Keep Conversation History, Init Script                              | Catalog Name, Model, Chat Type, Open AI Key, Context Window, Record Questions and Responses, Keep Conversation History      | Catalog Name=DALL-E-2-Model, Chat Type=completion, Open AI Key=Test123, Max Completion Tokens=20, Max Input Tokens=30, Context Window=5001, Record Questions and Responses=true, Keep Conversation History=false                                                                                 | DALL-E-2-Model           | NAME=DALL-E-2-Model, MODEL=dall-e-2, CHAT_TYPE=completion, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=true, CONTEXT_WINDOW=5001, MAX_TOKENS=20, MAX_INPUT_TOKENS=30                                 |
      | OpenAI           | text-embedding-3-large        | General | Catalog Name, Model, Tag       | Credentials | OpenAI API Key                                   | Settings | Max Tokens, Max Input Tokens, Record Questions and Responses, Init Script                                                                                    | Catalog Name, Model, Tag, OpenAI API Key, Record Questions and Responses, Init Script                                       | Catalog Name=text-embedding-large, OpenAI API Key=Test123, Max Input Tokens=5, Max Tokens=9, Record Questions and Responses=false                                                                                                                                                                | text-embedding-large     | NAME=text-embedding-large, MODEL=text-embedding-3-large, INIT_MODEL_ENGINE=from genai_client import OpenAiE, KEEP_INPUT_OUTPUT=false, MAX_TOKENS=9, MAX_INPUT_TOKENS=5, TAG=embeddings                                                                         |
      | OpenAI           | text-embedding-3-small        | General | Catalog Name, Model, Tag       | Credentials | OpenAI API Key                                   | Settings | Max Tokens, Max Input Tokens, Record Questions and Responses, Init Script                                                                                    | Catalog Name, Model, Tag, OpenAI API Key, Record Questions and Responses, Init Script                                       | Catalog Name=text-embedding-small, OpenAI API Key=Test123, Max Input Tokens=15, Max Tokens=19, Record Questions and Responses=false                                                                                                                                                              | text-embedding-small     | NAME=text-embedding-small, MODEL=text-embedding-3-small, INIT_MODEL_ENGINE=from genai_client import OpenAiE, KEEP_INPUT_OUTPUT=false, MAX_TOKENS=19, MAX_INPUT_TOKENS=15, TAG=embeddings                                                                       |
      | Google Vertex AI | Other Google Vertex AI models | General | Catalog Name, Model, Chat Type | Credentials | Project, GCP Region                              | Settings | Service Account Credentials, Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Max Input Tokens, Context Window, Init Script | Catalog Name, Model, Chat Type, Project, GCP Region, Record Questions and Responses, Keep Conversation History, Init Script | Catalog Name=Other-Google-Vertex-AI, Model=custom-model, Chat Type=generative, Project=Google, GCP Region=India, Service Account Credentials=Test@123, Max Input Tokens=20, Max Completion Tokens=20, Context Window=5000, Record Questions and Responses=false, Keep Conversation History=false | Other-Google-Vertex-AI   | NAME=Other-Google-Vertex-AI, MODEL=custom-model, CHAT_TYPE=generative, PROJECT=Google, GCP_REGION=India, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=5000, MAX_INPUT_TOKENS=20 |
      | Google Vertex AI | Gemini 2.5 Pro                | General | Catalog Name, Model, Chat Type | Credentials | Project, GCP Region                              | Settings | Service Account Credentials, Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Max Input Tokens, Context Window, Init Script | Catalog Name, Model, Chat Type, Project, GCP Region, Record Questions and Responses, Keep Conversation History, Init Script | Catalog Name=Gemini-2-5-Pro, Chat Type=code, Project=Google, GCP Region=India, Service Account Credentials=Test@123, Max Input Tokens=50, Max Completion Tokens=50, Context Window=2000, Record Questions and Responses=false, Keep Conversation History=true                                    | Gemini-2-5-Pro           | NAME=Gemini-2-5-Pro, MODEL=gemini-2.5-pro, CHAT_TYPE=code, PROJECT=Google, GCP_REGION=India, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=2000, MAX_INPUT_TOKENS=50              |
      | Google Vertex AI | Gemini Pro                    | General | Catalog Name, Model, Chat Type | Credentials | Project, GCP Region                              | Settings | Service Account Credentials, Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Max Input Tokens, Context Window, Init Script | Catalog Name, Model, Chat Type, Project, GCP Region, Record Questions and Responses, Keep Conversation History, Init Script | Catalog Name=Gemini-Pro, Chat Type=codechat, Project=Google, GCP Region=India, Service Account Credentials=Test@123, Max Input Tokens=25, Max Completion Tokens=25, Context Window=3000, Record Questions and Responses=true, Keep Conversation History=false                                    | Gemini-Pro               | NAME=Gemini-Pro, MODEL=gemini-pro, CHAT_TYPE=codechat, PROJECT=Google, GCP_REGION=India, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=true, CONTEXT_WINDOW=3000, MAX_INPUT_TOKENS=25                  |
      | Google Vertex AI | Gemini Ultra                  | General | Catalog Name, Model, Chat Type | Credentials | Project, GCP Region                              | Settings | Service Account Credentials, Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Max Input Tokens, Context Window, Init Script | Catalog Name, Model, Chat Type, Project, GCP Region, Record Questions and Responses, Keep Conversation History, Init Script | Catalog Name=Gemini-Ultra, Chat Type=chat, Project=Google, GCP Region=India, Service Account Credentials=Test@123, Max Input Tokens=35, Max Completion Tokens=35, Context Window=3500, Record Questions and Responses=false, Keep Conversation History=false                                     | Gemini-Ultra             | NAME=Gemini-Ultra, MODEL=gemini-ultra, CHAT_TYPE=chat, PROJECT=Google, GCP_REGION=India, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=3500, MAX_INPUT_TOKENS=35                 |
      | Google Vertex AI | Gemma 2b                      | General | Catalog Name, Model, Chat Type | Credentials | Project, GCP Region                              | Settings | Service Account Credentials, Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Max Input Tokens, Context Window, Init Script | Catalog Name, Model, Chat Type, Project, GCP Region, Record Questions and Responses, Keep Conversation History, Init Script | Catalog Name=Gemma-2b, Chat Type=generative, Project=Google, GCP Region=India, Service Account Credentials=Test@123, Max Input Tokens=20, Max Completion Tokens=20, Context Window=5000, Record Questions and Responses=false, Keep Conversation History=false                                   | Gemma-2b                 | NAME=Gemma-2b, MODEL=gemma-2b, CHAT_TYPE=generative, PROJECT=Google, GCP_REGION=India, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=5000, MAX_INPUT_TOKENS=20                   |
      | Google Vertex AI | Llama 2-7b                    | General | Catalog Name, Model, Chat Type | Credentials | Project, GCP Region                              | Settings | Service Account Credentials, Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Max Input Tokens, Context Window, Init Script | Catalog Name, Model, Chat Type, Project, GCP Region, Record Questions and Responses, Keep Conversation History, Init Script | Catalog Name=Llama-2-7b, Chat Type=generative, Project=Google, GCP Region=India, Service Account Credentials=Test@123, Max Input Tokens=20, Max Completion Tokens=20, Context Window=5000, Record Questions and Responses=false, Keep Conversation History=false                                 | Llama-2-7b               | NAME=Llama-2-7b, MODEL=llama-2-7b, CHAT_TYPE=generative, PROJECT=Google, GCP_REGION=India, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=5000, MAX_INPUT_TOKENS=20               |
      | Google Vertex AI | Llama 2-70b                   | General | Catalog Name, Model, Chat Type | Credentials | Project, GCP Region                              | Settings | Service Account Credentials, Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Max Input Tokens, Context Window, Init Script | Catalog Name, Model, Chat Type, Project, GCP Region, Record Questions and Responses, Keep Conversation History, Init Script | Catalog Name=Llama-2-70b, Chat Type=text, Project=Google, GCP Region=India, Service Account Credentials=Test@123, Max Input Tokens=49, Max Completion Tokens=49, Context Window=4900, Record Questions and Responses=true, Keep Conversation History=true                                        | Llama-2-70b              | NAME=Llama-2-70b, MODEL=llama-2-70b, CHAT_TYPE=text, PROJECT=Google, GCP_REGION=India, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=true, CONTEXT_WINDOW=4900, MAX_INPUT_TOKENS=49                     |
      | Google Vertex AI | PaLM 2 Bison                  | General | Catalog Name, Model, Chat Type | Credentials | Project, GCP Region                              | Settings | Service Account Credentials, Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Max Input Tokens, Context Window, Init Script | Catalog Name, Model, Chat Type, Project, GCP Region, Record Questions and Responses, Keep Conversation History, Init Script | Catalog Name=PaLM-2-Bison, Chat Type=generative, Project=Google, GCP Region=India, Service Account Credentials=Test@123, Max Input Tokens=20, Max Completion Tokens=20, Context Window=5000, Record Questions and Responses=false, Keep Conversation History=false                               | PaLM-2-Bison             | NAME=PaLM-2-Bison, MODEL=text-bison, CHAT_TYPE=generative, PROJECT=Google, GCP_REGION=India, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=5000, MAX_INPUT_TOKENS=20             |
      | Google Vertex AI | PaLM 2 Bison (32k)            | General | Catalog Name, Model, Chat Type | Credentials | Project, GCP Region                              | Settings | Service Account Credentials, Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Max Input Tokens, Context Window, Init Script | Catalog Name, Model, Chat Type, Project, GCP Region, Record Questions and Responses, Keep Conversation History, Init Script | Catalog Name=PaLM-2-Bison-32k , Chat Type=chat, Project=Google, GCP Region=India, Service Account Credentials=Test@123, Max Input Tokens=43, Max Completion Tokens=43, Context Window=4300, Record Questions and Responses=true, Keep Conversation History=false                                 | PaLM-2-Bison-32k         | NAME=PaLM-2-Bison-32k , MODEL=text-bison-32k, CHAT_TYPE=chat, PROJECT=Google, GCP_REGION=India, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=true, CONTEXT_WINDOW=4300, MAX_INPUT_TOKENS=43           |
      | Google Vertex AI | Code Generation Bison         | General | Catalog Name, Model, Chat Type | Credentials | Project, GCP Region                              | Settings | Service Account Credentials, Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Max Input Tokens, Context Window, Init Script | Catalog Name, Model, Chat Type, Project, GCP Region, Record Questions and Responses, Keep Conversation History, Init Script | Catalog Name=Code-Generation-Bison, Chat Type=generative, Project=Google, GCP Region=India, Service Account Credentials=Test@123, Max Input Tokens=20, Max Completion Tokens=20, Context Window=5000, Record Questions and Responses=false, Keep Conversation History=false                      | Code-Generation-Bison    | NAME=Code-Generation-Bison, MODEL=code-bison, CHAT_TYPE=generative, PROJECT=Google, GCP_REGION=India, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=5000, MAX_INPUT_TOKENS=20    |
      | Google Vertex AI | Mistral                       | General | Catalog Name, Model, Chat Type | Credentials | Project, GCP Region                              | Settings | Service Account Credentials, Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Max Input Tokens, Context Window, Init Script | Catalog Name, Model, Chat Type, Project, GCP Region, Record Questions and Responses, Keep Conversation History, Init Script | Catalog Name=Mistral, Chat Type=codechat, Project=Google, GCP Region=India, Service Account Credentials=Test@123, Max Input Tokens=22, Max Completion Tokens=22, Context Window=2200, Record Questions and Responses=false, Keep Conversation History=true                                       | Mistral                  | NAME=Mistral, MODEL=mistral-7b, CHAT_TYPE=codechat, PROJECT=Google, GCP_REGION=India, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=2200, MAX_INPUT_TOKENS=22                     |
      | AWS Bedrock      | Other AWS Bedrock models      | General | Catalog Name, Model ID         | Credentials | AWS Access Key ID, AWS Secret Access Key, Region | Settings | Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Context Window, Init Script                                                | Catalog Name, Model ID, Region, Record Questions and Responses, Keep Conversation History, Init Script                      | Catalog Name=Other-AWS-Bedrock-models, Model ID=1, AWS Access Key ID=123, AWS Secret Access Key=Test@123, Region=Asia, Max Completion Tokens=22, Context Window=2200, Record Questions and Responses=false, Keep Conversation History=true                                                       | Other-AWS-Bedrock-models | NAME=Other-AWS-Bedrock-models, MODEL=1, AWS_REGION=Asia, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=2200, MAX_TOKENS=22                                                        |
      | AWS Bedrock      | Claude 3 Opus                 | General | Catalog Name, Model ID         | Credentials | AWS Access Key ID, AWS Secret Access Key, Region | Settings | Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Context Window, Init Script                                                | Catalog Name, Model ID, Region, Record Questions and Responses, Keep Conversation History, Init Script                      | Catalog Name=Claude-3-Opus, AWS Access Key ID=123, AWS Secret Access Key=Test@123, Region=Asia, Max Completion Tokens=22, Context Window=2200, Record Questions and Responses=false, Keep Conversation History=true                                                                              | Claude-3-Opus            | NAME=Claude-3-Opus, MODEL=anthropic.claude-3-opus-20240229-v1:0, AWS_REGION=Asia, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=2200, MAX_TOKENS=22                               |
      | AWS Bedrock      | Claude 3 Sonnet               | General | Catalog Name, Model ID         | Credentials | AWS Access Key ID, AWS Secret Access Key, Region | Settings | Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Context Window, Init Script                                                | Catalog Name, Model ID, Region, Record Questions and Responses, Keep Conversation History, Init Script                      | Catalog Name=Claude-3-Sonnet, AWS Access Key ID=123, AWS Secret Access Key=Test@123, Region=Asia, Max Completion Tokens=11, Context Window=1100, Record Questions and Responses=false, Keep Conversation History=true                                                                            | Claude-3-Sonnet          | NAME=Claude-3-Sonnet, MODEL=anthropic.claude-3-sonnet-20240229-v1:0, AWS_REGION=Asia, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=1100, MAX_TOKENS=11                           |
      | AWS Bedrock      | Claude 3 Haiku                | General | Catalog Name, Model ID         | Credentials | AWS Access Key ID, AWS Secret Access Key, Region | Settings | Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Context Window, Init Script                                                | Catalog Name, Model ID, Region, Record Questions and Responses, Keep Conversation History, Init Script                      | Catalog Name=Claude-3-Haiku, AWS Access Key ID=123, AWS Secret Access Key=Test@123, Region=Asia, Max Completion Tokens=11, Context Window=1100, Record Questions and Responses=false, Keep Conversation History=true                                                                             | Claude-3-Haiku           | NAME=Claude-3-Haiku, MODEL=anthropic.claude-3-haiku-20240307-v1:0, AWS_REGION=Asia, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=1100, MAX_TOKENS=11                             |
      | AWS Bedrock      | Claude 2.0                    | General | Catalog Name, Model ID         | Credentials | AWS Access Key ID, AWS Secret Access Key, Region | Settings | Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Context Window, Init Script                                                | Catalog Name, Model ID, Region, Record Questions and Responses, Keep Conversation History, Init Script                      | Catalog Name=Claude-2-Model, AWS Access Key ID=123, AWS Secret Access Key=Test@123, Region=Asia, Max Completion Tokens=9, Context Window=99999, Record Questions and Responses=false, Keep Conversation History=true                                                                             | Claude-2-Model           | NAME=Claude-2-Model, MODEL=anthropic.claude-v2, AWS_REGION=Asia, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=99999, MAX_TOKENS=9                                                |
      | AWS Bedrock      | Jurassic-2 Ultra              | General | Catalog Name, Model ID         | Credentials | AWS Access Key ID, AWS Secret Access Key, Region | Settings | Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Context Window, Init Script                                                | Catalog Name, Model ID, Region, Record Questions and Responses, Keep Conversation History, Init Script                      | Catalog Name=Jurassic-2-Ultra, AWS Access Key ID=123, AWS Secret Access Key=Test@123, Region=Asia, Max Completion Tokens=9, Context Window=99999, Record Questions and Responses=false, Keep Conversation History=true                                                                           | Jurassic-2-Ultra         | NAME=Jurassic-2-Ultra, MODEL=ai21.j2-ultra-v1, AWS_REGION=Asia, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=99999, MAX_TOKENS=9                                                 |
      | AWS Bedrock      | Jurassic-2 Mid                | General | Catalog Name, Model ID         | Credentials | AWS Access Key ID, AWS Secret Access Key, Region | Settings | Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Context Window, Init Script                                                | Catalog Name, Model ID, Region, Record Questions and Responses, Keep Conversation History, Init Script                      | Catalog Name=Jurassic-2-Mid, AWS Access Key ID=123, AWS Secret Access Key=Test@123, Region=Asia, Max Completion Tokens=9, Context Window=99999, Record Questions and Responses=false, Keep Conversation History=true                                                                             | Jurassic-2-Mid           | NAME=Jurassic-2-Mid, MODEL=ai21.j2-mid-v1, AWS_REGION=Asia, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=99999, MAX_TOKENS=9                                                     |
      | AWS Bedrock      | Titan Text G1 Express         | General | Catalog Name, Model ID         | Credentials | AWS Access Key ID, AWS Secret Access Key, Region | Settings | Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Context Window, Init Script                                                | Catalog Name, Model ID, Region, Record Questions and Responses, Keep Conversation History, Init Script                      | Catalog Name=Titan-Text-G1-Express, AWS Access Key ID=123, AWS Secret Access Key=Test@123, Region=Asia, Max Completion Tokens=99, Context Window=999, Record Questions and Responses=false, Keep Conversation History=true                                                                       | Titan-Text-G1-Express    | NAME=Titan-Text-G1-Express, MODEL=amazon.titan-text-express-v1, AWS_REGION=Asia, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=true, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=999, MAX_TOKENS=99                                 |
      | AWS Bedrock      | Titan Embeddings (text)       | General | Catalog Name, Model ID         | Credentials | AWS Access Key ID, AWS Secret Access Key, Region | Settings | Record Questions and Responses, Keep Conversation History, Max Completion Tokens, Context Window, Init Script                                                | Catalog Name, Model ID, Region, Record Questions and Responses, Keep Conversation History, Init Script                      | Catalog Name=Titan-Embeddings-text, AWS Access Key ID=123, AWS Secret Access Key=Test@123, Region=Asia, Max Completion Tokens=8, Context Window=1000, Record Questions and Responses=false, Keep Conversation History=false                                                                      | Titan-Embeddings-text    | NAME=Titan-Embeddings-text, MODEL=amazon.titan-embed-text-v1, AWS_REGION=Asia, INIT_MODEL_ENGINE=import genai_client;${VAR_NAME}, KEEP_CONVERSATION_HISTORY=false, KEEP_INPUT_OUTPUT=false, CONTEXT_WINDOW=1000, MAX_TOKENS=8                                  |
